import {ModelReference} from 'genkit';
import {GenkitPlugin, GenkitPluginV2} from 'genkit/plugin';
import {RateLimiter} from 'limiter';
import {PromptDataMessage} from '../llm-runner.js';
import {LlmResponseFile} from '../../shared-interfaces.js';

export interface RateLimitConfig {
  requestPerMinute: RateLimiter;
  tokensPerMinute: RateLimiter;
  countTokens(prompt: PromptDataForCounting): Promise<number | null>;
}

export interface PromptDataForCounting {
  prompt: string;
  messages: PromptDataMessage[];
}

/** Abstraction around an LLM provider. */
export abstract class GenkitModelProvider {
  abstract readonly apiKeyVariableName: string;
  protected abstract readonly models: Record<string, () => ModelReference<any>>;
  protected abstract readonly rateLimitConfig: Record<string, RateLimitConfig>;

  /** Creates a model instance, if the the provider supports the model. */
  createModel(name: string): ModelReference<any> | null {
    return this.supportsModel(name) ? this.models[name]() : null;
  }

  /** Returns whether the provider supports a specific model. */
  supportsModel(name: string): boolean {
    return this.models.hasOwnProperty(name);
  }

  /** Gets the names of all models supported by the provider. */
  getSupportedModels(): string[] {
    return Object.keys(this.models);
  }

  /** Gets the API key associated with this provider. */
  getApiKey(): string | null {
    return process.env[this.apiKeyVariableName] || null;
  }

  /** Gets a Genkit plugin that can be used to query the provider. */
  getPlugin(): GenkitPlugin | GenkitPluginV2 | null {
    const key = this.getApiKey();
    return key ? this.pluginFactory(key) : null;
  }

  /**
   * Checks whether files generated by the LLM are valid.
   * If not, the Genkit runner will throw an error.
   */
  abstract validateGeneratedFiles(files: LlmResponseFile[]): boolean;

  protected abstract pluginFactory(apiKey: string): GenkitPlugin | GenkitPluginV2;

  abstract getModelSpecificConfig(opts: {includeThoughts?: boolean}, modelName: string): object;

  async rateLimit(prompt: PromptDataForCounting, model: ModelReference<any>): Promise<void> {
    const config = this.rateLimitConfig[model.name];

    if (config) {
      await config.requestPerMinute.removeTokens(1);
      const tokenCount = (await config.countTokens(prompt)) ?? 0;
      await config.tokensPerMinute.removeTokens(tokenCount);
    }
  }
}
